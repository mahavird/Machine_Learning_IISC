{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "#from utils import plot_images\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = dsets.MNIST(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    print len(train_dataset)\n",
    "    valid_dataset = dsets.MNIST(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=9, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory,\n",
    "        )\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy().transpose([0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "\n",
    "    return (train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "6000\n",
      "54000\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "\n",
    "train_loader,test_loader = get_train_valid_loader('./data',\n",
    "                           1,\n",
    "                           False,\n",
    "                           1,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=1,\n",
    "                           pin_memory=True)\n",
    "#train_dataset = dsets.MNIST(root='./data',train=True, transform=transforms.ToTensor(),download=True)\n",
    "print len(test_loader)\n",
    "print len(train_loader)\n",
    "\n",
    "test_final_dataset = dsets.MNIST(root='./data',train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3777fa679933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "print (train_loader.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "#                                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_final_loader = torch.utils.data.DataLoader(dataset=test_final_dataset, \n",
    "                                          batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.py:97: UserWarning: \n",
      "    Found GPU0 GeForce 940MX which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/2], Step: [100/540], Loss: 4.0922\n",
      "Epoch: [1/2], Step: [200/540], Loss: 0.1564\n",
      "Epoch: [1/2], Step: [300/540], Loss: 2.3126\n",
      "Epoch: [1/2], Step: [400/540], Loss: 0.0387\n",
      "Epoch: [1/2], Step: [500/540], Loss: 0.9841\n",
      "Epoch: [1/2], Step: [600/540], Loss: 3.5838\n",
      "Epoch: [1/2], Step: [700/540], Loss: 0.1118\n",
      "Epoch: [1/2], Step: [800/540], Loss: 0.6058\n",
      "Epoch: [1/2], Step: [900/540], Loss: 0.4226\n",
      "Epoch: [1/2], Step: [1000/540], Loss: 0.0811\n",
      "Epoch: [1/2], Step: [1100/540], Loss: 0.2246\n",
      "Epoch: [1/2], Step: [1200/540], Loss: 0.6033\n",
      "Epoch: [1/2], Step: [1300/540], Loss: 0.2885\n",
      "Epoch: [1/2], Step: [1400/540], Loss: 0.1419\n",
      "Epoch: [1/2], Step: [1500/540], Loss: 0.7785\n",
      "Epoch: [1/2], Step: [1600/540], Loss: 0.2981\n",
      "Epoch: [1/2], Step: [1700/540], Loss: 0.0120\n",
      "Epoch: [1/2], Step: [1800/540], Loss: 0.0007\n",
      "Epoch: [1/2], Step: [1900/540], Loss: 0.2216\n",
      "Epoch: [1/2], Step: [2000/540], Loss: 5.0303\n",
      "Epoch: [1/2], Step: [2100/540], Loss: 0.0842\n",
      "Epoch: [1/2], Step: [2200/540], Loss: 0.0435\n",
      "Epoch: [1/2], Step: [2300/540], Loss: 0.1332\n",
      "Epoch: [1/2], Step: [2400/540], Loss: 0.0178\n",
      "Epoch: [1/2], Step: [2500/540], Loss: 0.0580\n",
      "Epoch: [1/2], Step: [2600/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [2700/540], Loss: 1.0973\n",
      "Epoch: [1/2], Step: [2800/540], Loss: 0.4860\n",
      "Epoch: [1/2], Step: [2900/540], Loss: 4.6521\n",
      "Epoch: [1/2], Step: [3000/540], Loss: 0.0247\n",
      "Epoch: [1/2], Step: [3100/540], Loss: 0.0258\n",
      "Epoch: [1/2], Step: [3200/540], Loss: 1.2847\n",
      "Epoch: [1/2], Step: [3300/540], Loss: 0.0050\n",
      "Epoch: [1/2], Step: [3400/540], Loss: 0.2681\n",
      "Epoch: [1/2], Step: [3500/540], Loss: 0.0160\n",
      "Epoch: [1/2], Step: [3600/540], Loss: 0.0015\n",
      "Epoch: [1/2], Step: [3700/540], Loss: 0.1282\n",
      "Epoch: [1/2], Step: [3800/540], Loss: 0.0996\n",
      "Epoch: [1/2], Step: [3900/540], Loss: 0.0033\n",
      "Epoch: [1/2], Step: [4000/540], Loss: 0.1140\n",
      "Epoch: [1/2], Step: [4100/540], Loss: 0.0011\n",
      "Epoch: [1/2], Step: [4200/540], Loss: 0.5577\n",
      "Epoch: [1/2], Step: [4300/540], Loss: 0.1747\n",
      "Epoch: [1/2], Step: [4400/540], Loss: 0.0037\n",
      "Epoch: [1/2], Step: [4500/540], Loss: 0.0085\n",
      "Epoch: [1/2], Step: [4600/540], Loss: 1.8137\n",
      "Epoch: [1/2], Step: [4700/540], Loss: 0.1858\n",
      "Epoch: [1/2], Step: [4800/540], Loss: 0.9159\n",
      "Epoch: [1/2], Step: [4900/540], Loss: 1.1439\n",
      "Epoch: [1/2], Step: [5000/540], Loss: 0.0117\n",
      "Epoch: [1/2], Step: [5100/540], Loss: 0.0065\n",
      "Epoch: [1/2], Step: [5200/540], Loss: 0.1653\n",
      "Epoch: [1/2], Step: [5300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [5400/540], Loss: 0.0061\n",
      "Epoch: [1/2], Step: [5500/540], Loss: 0.0068\n",
      "Epoch: [1/2], Step: [5600/540], Loss: 0.0059\n",
      "Epoch: [1/2], Step: [5700/540], Loss: 0.3242\n",
      "Epoch: [1/2], Step: [5800/540], Loss: 0.2642\n",
      "Epoch: [1/2], Step: [5900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [6000/540], Loss: 1.4347\n",
      "Epoch: [1/2], Step: [6100/540], Loss: 0.0029\n",
      "Epoch: [1/2], Step: [6200/540], Loss: 4.2541\n",
      "Epoch: [1/2], Step: [6300/540], Loss: 0.6368\n",
      "Epoch: [1/2], Step: [6400/540], Loss: 0.0065\n",
      "Epoch: [1/2], Step: [6500/540], Loss: 0.0091\n",
      "Epoch: [1/2], Step: [6600/540], Loss: 0.0141\n",
      "Epoch: [1/2], Step: [6700/540], Loss: 2.3545\n",
      "Epoch: [1/2], Step: [6800/540], Loss: 0.0034\n",
      "Epoch: [1/2], Step: [6900/540], Loss: 0.0022\n",
      "Epoch: [1/2], Step: [7000/540], Loss: 0.0125\n",
      "Epoch: [1/2], Step: [7100/540], Loss: 0.0082\n",
      "Epoch: [1/2], Step: [7200/540], Loss: 0.0319\n",
      "Epoch: [1/2], Step: [7300/540], Loss: 0.1325\n",
      "Epoch: [1/2], Step: [7400/540], Loss: 0.0014\n",
      "Epoch: [1/2], Step: [7500/540], Loss: 0.7104\n",
      "Epoch: [1/2], Step: [7600/540], Loss: 0.0072\n",
      "Epoch: [1/2], Step: [7700/540], Loss: 0.0181\n",
      "Epoch: [1/2], Step: [7800/540], Loss: 0.5530\n",
      "Epoch: [1/2], Step: [7900/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [8000/540], Loss: 0.8162\n",
      "Epoch: [1/2], Step: [8100/540], Loss: 3.8070\n",
      "Epoch: [1/2], Step: [8200/540], Loss: 0.0005\n",
      "Epoch: [1/2], Step: [8300/540], Loss: 0.0021\n",
      "Epoch: [1/2], Step: [8400/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [8500/540], Loss: 0.0072\n",
      "Epoch: [1/2], Step: [8600/540], Loss: 0.1029\n",
      "Epoch: [1/2], Step: [8700/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [8800/540], Loss: 0.0589\n",
      "Epoch: [1/2], Step: [8900/540], Loss: 0.0084\n",
      "Epoch: [1/2], Step: [9000/540], Loss: 0.2806\n",
      "Epoch: [1/2], Step: [9100/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [9200/540], Loss: 0.0021\n",
      "Epoch: [1/2], Step: [9300/540], Loss: 0.0074\n",
      "Epoch: [1/2], Step: [9400/540], Loss: 0.0103\n",
      "Epoch: [1/2], Step: [9500/540], Loss: 0.0139\n",
      "Epoch: [1/2], Step: [9600/540], Loss: 1.1640\n",
      "Epoch: [1/2], Step: [9700/540], Loss: 0.0109\n",
      "Epoch: [1/2], Step: [9800/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [9900/540], Loss: 0.0785\n",
      "Epoch: [1/2], Step: [10000/540], Loss: 0.0159\n",
      "Epoch: [1/2], Step: [10100/540], Loss: 0.0238\n",
      "Epoch: [1/2], Step: [10200/540], Loss: 2.4504\n",
      "Epoch: [1/2], Step: [10300/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [10400/540], Loss: 0.0131\n",
      "Epoch: [1/2], Step: [10500/540], Loss: 0.0053\n",
      "Epoch: [1/2], Step: [10600/540], Loss: 1.2538\n",
      "Epoch: [1/2], Step: [10700/540], Loss: 0.0041\n",
      "Epoch: [1/2], Step: [10800/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [10900/540], Loss: 0.0007\n",
      "Epoch: [1/2], Step: [11000/540], Loss: 0.0014\n",
      "Epoch: [1/2], Step: [11100/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [11200/540], Loss: 0.0183\n",
      "Epoch: [1/2], Step: [11300/540], Loss: 0.0117\n",
      "Epoch: [1/2], Step: [11400/540], Loss: 0.4010\n",
      "Epoch: [1/2], Step: [11500/540], Loss: 0.0169\n",
      "Epoch: [1/2], Step: [11600/540], Loss: 0.0032\n",
      "Epoch: [1/2], Step: [11700/540], Loss: 0.0626\n",
      "Epoch: [1/2], Step: [11800/540], Loss: 0.0590\n",
      "Epoch: [1/2], Step: [11900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [12000/540], Loss: 0.0278\n",
      "Epoch: [1/2], Step: [12100/540], Loss: 0.4885\n",
      "Epoch: [1/2], Step: [12200/540], Loss: 0.0070\n",
      "Epoch: [1/2], Step: [12300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [12400/540], Loss: 0.0058\n",
      "Epoch: [1/2], Step: [12500/540], Loss: 0.0140\n",
      "Epoch: [1/2], Step: [12600/540], Loss: 0.0279\n",
      "Epoch: [1/2], Step: [12700/540], Loss: 0.5918\n",
      "Epoch: [1/2], Step: [12800/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [12900/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [13000/540], Loss: 0.0858\n",
      "Epoch: [1/2], Step: [13100/540], Loss: 4.0418\n",
      "Epoch: [1/2], Step: [13200/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [13300/540], Loss: 0.0013\n",
      "Epoch: [1/2], Step: [13400/540], Loss: 0.2335\n",
      "Epoch: [1/2], Step: [13500/540], Loss: 0.0032\n",
      "Epoch: [1/2], Step: [13600/540], Loss: 0.1082\n",
      "Epoch: [1/2], Step: [13700/540], Loss: 0.0801\n",
      "Epoch: [1/2], Step: [13800/540], Loss: 0.0514\n",
      "Epoch: [1/2], Step: [13900/540], Loss: 0.0554\n",
      "Epoch: [1/2], Step: [14000/540], Loss: 0.0153\n",
      "Epoch: [1/2], Step: [14100/540], Loss: 0.0594\n",
      "Epoch: [1/2], Step: [14200/540], Loss: 0.0263\n",
      "Epoch: [1/2], Step: [14300/540], Loss: 0.1283\n",
      "Epoch: [1/2], Step: [14400/540], Loss: 0.0073\n",
      "Epoch: [1/2], Step: [14500/540], Loss: 5.0885\n",
      "Epoch: [1/2], Step: [14600/540], Loss: 0.0918\n",
      "Epoch: [1/2], Step: [14700/540], Loss: 0.1492\n",
      "Epoch: [1/2], Step: [14800/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [14900/540], Loss: 0.0381\n",
      "Epoch: [1/2], Step: [15000/540], Loss: 2.8504\n",
      "Epoch: [1/2], Step: [15100/540], Loss: 0.2913\n",
      "Epoch: [1/2], Step: [15200/540], Loss: 0.1139\n",
      "Epoch: [1/2], Step: [15300/540], Loss: 0.0191\n",
      "Epoch: [1/2], Step: [15400/540], Loss: 0.0020\n",
      "Epoch: [1/2], Step: [15500/540], Loss: 0.1429\n",
      "Epoch: [1/2], Step: [15600/540], Loss: 0.0014\n",
      "Epoch: [1/2], Step: [15700/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [15800/540], Loss: 0.0017\n",
      "Epoch: [1/2], Step: [15900/540], Loss: 0.0016\n",
      "Epoch: [1/2], Step: [16000/540], Loss: 0.3961\n",
      "Epoch: [1/2], Step: [16100/540], Loss: 0.5551\n",
      "Epoch: [1/2], Step: [16200/540], Loss: 0.3552\n",
      "Epoch: [1/2], Step: [16300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [16400/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [16500/540], Loss: 0.3224\n",
      "Epoch: [1/2], Step: [16600/540], Loss: 0.0010\n",
      "Epoch: [1/2], Step: [16700/540], Loss: 4.9557\n",
      "Epoch: [1/2], Step: [16800/540], Loss: 0.0192\n",
      "Epoch: [1/2], Step: [16900/540], Loss: 0.0497\n",
      "Epoch: [1/2], Step: [17000/540], Loss: 0.0008\n",
      "Epoch: [1/2], Step: [17100/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [17200/540], Loss: 0.0008\n",
      "Epoch: [1/2], Step: [17300/540], Loss: 1.3503\n",
      "Epoch: [1/2], Step: [17400/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [17500/540], Loss: 0.0012\n",
      "Epoch: [1/2], Step: [17600/540], Loss: 0.0459\n",
      "Epoch: [1/2], Step: [17700/540], Loss: 0.0027\n",
      "Epoch: [1/2], Step: [17800/540], Loss: 0.0031\n",
      "Epoch: [1/2], Step: [17900/540], Loss: 0.0120\n",
      "Epoch: [1/2], Step: [18000/540], Loss: 0.0006\n",
      "Epoch: [1/2], Step: [18100/540], Loss: 0.0007\n",
      "Epoch: [1/2], Step: [18200/540], Loss: 0.2833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/2], Step: [18300/540], Loss: 0.0049\n",
      "Epoch: [1/2], Step: [18400/540], Loss: 0.1467\n",
      "Epoch: [1/2], Step: [18500/540], Loss: 0.0112\n",
      "Epoch: [1/2], Step: [18600/540], Loss: 0.1055\n",
      "Epoch: [1/2], Step: [18700/540], Loss: 0.0021\n",
      "Epoch: [1/2], Step: [18800/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [18900/540], Loss: 0.1106\n",
      "Epoch: [1/2], Step: [19000/540], Loss: 0.5662\n",
      "Epoch: [1/2], Step: [19100/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [19200/540], Loss: 0.6719\n",
      "Epoch: [1/2], Step: [19300/540], Loss: 0.0044\n",
      "Epoch: [1/2], Step: [19400/540], Loss: 0.0231\n",
      "Epoch: [1/2], Step: [19500/540], Loss: 0.1331\n",
      "Epoch: [1/2], Step: [19600/540], Loss: 0.0183\n",
      "Epoch: [1/2], Step: [19700/540], Loss: 0.0017\n",
      "Epoch: [1/2], Step: [19800/540], Loss: 0.0029\n",
      "Epoch: [1/2], Step: [19900/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [20000/540], Loss: 0.0295\n",
      "Epoch: [1/2], Step: [20100/540], Loss: 0.0075\n",
      "Epoch: [1/2], Step: [20200/540], Loss: 1.2554\n",
      "Epoch: [1/2], Step: [20300/540], Loss: 0.0338\n",
      "Epoch: [1/2], Step: [20400/540], Loss: 0.0166\n",
      "Epoch: [1/2], Step: [20500/540], Loss: 0.2404\n",
      "Epoch: [1/2], Step: [20600/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [20700/540], Loss: 0.0889\n",
      "Epoch: [1/2], Step: [20800/540], Loss: 0.3568\n",
      "Epoch: [1/2], Step: [20900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [21000/540], Loss: 0.2532\n",
      "Epoch: [1/2], Step: [21100/540], Loss: 0.0220\n",
      "Epoch: [1/2], Step: [21200/540], Loss: 0.2380\n",
      "Epoch: [1/2], Step: [21300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [21400/540], Loss: 0.0727\n",
      "Epoch: [1/2], Step: [21500/540], Loss: 0.0740\n",
      "Epoch: [1/2], Step: [21600/540], Loss: 0.3553\n",
      "Epoch: [1/2], Step: [21700/540], Loss: 0.0162\n",
      "Epoch: [1/2], Step: [21800/540], Loss: 0.0060\n",
      "Epoch: [1/2], Step: [21900/540], Loss: 0.1002\n",
      "Epoch: [1/2], Step: [22000/540], Loss: 0.3937\n",
      "Epoch: [1/2], Step: [22100/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [22200/540], Loss: 0.0928\n",
      "Epoch: [1/2], Step: [22300/540], Loss: 0.0601\n",
      "Epoch: [1/2], Step: [22400/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [22500/540], Loss: 0.0050\n",
      "Epoch: [1/2], Step: [22600/540], Loss: 0.0841\n",
      "Epoch: [1/2], Step: [22700/540], Loss: 0.8662\n",
      "Epoch: [1/2], Step: [22800/540], Loss: 0.4763\n",
      "Epoch: [1/2], Step: [22900/540], Loss: 0.0014\n",
      "Epoch: [1/2], Step: [23000/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [23100/540], Loss: 0.0005\n",
      "Epoch: [1/2], Step: [23200/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [23300/540], Loss: 0.0295\n",
      "Epoch: [1/2], Step: [23400/540], Loss: 3.6221\n",
      "Epoch: [1/2], Step: [23500/540], Loss: 0.0365\n",
      "Epoch: [1/2], Step: [23600/540], Loss: 3.6737\n",
      "Epoch: [1/2], Step: [23700/540], Loss: 2.6361\n",
      "Epoch: [1/2], Step: [23800/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [23900/540], Loss: 3.7352\n",
      "Epoch: [1/2], Step: [24000/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [24100/540], Loss: 0.0008\n",
      "Epoch: [1/2], Step: [24200/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [24300/540], Loss: 0.0051\n",
      "Epoch: [1/2], Step: [24400/540], Loss: 0.1264\n",
      "Epoch: [1/2], Step: [24500/540], Loss: 0.0057\n",
      "Epoch: [1/2], Step: [24600/540], Loss: 0.0671\n",
      "Epoch: [1/2], Step: [24700/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [24800/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [24900/540], Loss: 0.0021\n",
      "Epoch: [1/2], Step: [25000/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [25100/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [25200/540], Loss: 0.0012\n",
      "Epoch: [1/2], Step: [25300/540], Loss: 3.5646\n",
      "Epoch: [1/2], Step: [25400/540], Loss: 0.0035\n",
      "Epoch: [1/2], Step: [25500/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [25600/540], Loss: 0.3395\n",
      "Epoch: [1/2], Step: [25700/540], Loss: 0.0011\n",
      "Epoch: [1/2], Step: [25800/540], Loss: 6.4409\n",
      "Epoch: [1/2], Step: [25900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [26000/540], Loss: 0.1947\n",
      "Epoch: [1/2], Step: [26100/540], Loss: 3.0771\n",
      "Epoch: [1/2], Step: [26200/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [26300/540], Loss: 0.0008\n",
      "Epoch: [1/2], Step: [26400/540], Loss: 0.0783\n",
      "Epoch: [1/2], Step: [26500/540], Loss: 0.0227\n",
      "Epoch: [1/2], Step: [26600/540], Loss: 0.0119\n",
      "Epoch: [1/2], Step: [26700/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [26800/540], Loss: 0.2134\n",
      "Epoch: [1/2], Step: [26900/540], Loss: 0.1029\n",
      "Epoch: [1/2], Step: [27000/540], Loss: 0.0388\n",
      "Epoch: [1/2], Step: [27100/540], Loss: 0.0825\n",
      "Epoch: [1/2], Step: [27200/540], Loss: 0.0253\n",
      "Epoch: [1/2], Step: [27300/540], Loss: 0.0013\n",
      "Epoch: [1/2], Step: [27400/540], Loss: 0.0261\n",
      "Epoch: [1/2], Step: [27500/540], Loss: 0.0782\n",
      "Epoch: [1/2], Step: [27600/540], Loss: 0.5224\n",
      "Epoch: [1/2], Step: [27700/540], Loss: 0.2639\n",
      "Epoch: [1/2], Step: [27800/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [27900/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [28000/540], Loss: 0.1944\n",
      "Epoch: [1/2], Step: [28100/540], Loss: 0.3872\n",
      "Epoch: [1/2], Step: [28200/540], Loss: 0.3274\n",
      "Epoch: [1/2], Step: [28300/540], Loss: 0.0011\n",
      "Epoch: [1/2], Step: [28400/540], Loss: 0.0119\n",
      "Epoch: [1/2], Step: [28500/540], Loss: 1.9273\n",
      "Epoch: [1/2], Step: [28600/540], Loss: 0.0244\n",
      "Epoch: [1/2], Step: [28700/540], Loss: 0.0324\n",
      "Epoch: [1/2], Step: [28800/540], Loss: 0.0059\n",
      "Epoch: [1/2], Step: [28900/540], Loss: 2.2582\n",
      "Epoch: [1/2], Step: [29000/540], Loss: 0.0091\n",
      "Epoch: [1/2], Step: [29100/540], Loss: 0.4511\n",
      "Epoch: [1/2], Step: [29200/540], Loss: 0.4941\n",
      "Epoch: [1/2], Step: [29300/540], Loss: 0.0012\n",
      "Epoch: [1/2], Step: [29400/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [29500/540], Loss: 0.0051\n",
      "Epoch: [1/2], Step: [29600/540], Loss: 0.9614\n",
      "Epoch: [1/2], Step: [29700/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [29800/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [29900/540], Loss: 0.0279\n",
      "Epoch: [1/2], Step: [30000/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [30100/540], Loss: 1.3769\n",
      "Epoch: [1/2], Step: [30200/540], Loss: 1.0938\n",
      "Epoch: [1/2], Step: [30300/540], Loss: 0.0657\n",
      "Epoch: [1/2], Step: [30400/540], Loss: 1.0032\n",
      "Epoch: [1/2], Step: [30500/540], Loss: 6.5366\n",
      "Epoch: [1/2], Step: [30600/540], Loss: 0.0213\n",
      "Epoch: [1/2], Step: [30700/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [30800/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [30900/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [31000/540], Loss: 0.0247\n",
      "Epoch: [1/2], Step: [31100/540], Loss: 0.0183\n",
      "Epoch: [1/2], Step: [31200/540], Loss: 0.1177\n",
      "Epoch: [1/2], Step: [31300/540], Loss: 0.5193\n",
      "Epoch: [1/2], Step: [31400/540], Loss: 0.0205\n",
      "Epoch: [1/2], Step: [31500/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [31600/540], Loss: 0.0006\n",
      "Epoch: [1/2], Step: [31700/540], Loss: 1.6611\n",
      "Epoch: [1/2], Step: [31800/540], Loss: 1.3475\n",
      "Epoch: [1/2], Step: [31900/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [32000/540], Loss: 0.0073\n",
      "Epoch: [1/2], Step: [32100/540], Loss: 0.0094\n",
      "Epoch: [1/2], Step: [32200/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [32300/540], Loss: 0.0021\n",
      "Epoch: [1/2], Step: [32400/540], Loss: 0.2402\n",
      "Epoch: [1/2], Step: [32500/540], Loss: 0.0030\n",
      "Epoch: [1/2], Step: [32600/540], Loss: 0.0604\n",
      "Epoch: [1/2], Step: [32700/540], Loss: 0.0299\n",
      "Epoch: [1/2], Step: [32800/540], Loss: 3.9003\n",
      "Epoch: [1/2], Step: [32900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [33000/540], Loss: 0.0024\n",
      "Epoch: [1/2], Step: [33100/540], Loss: 0.0137\n",
      "Epoch: [1/2], Step: [33200/540], Loss: 0.0023\n",
      "Epoch: [1/2], Step: [33300/540], Loss: 0.0035\n",
      "Epoch: [1/2], Step: [33400/540], Loss: 2.7240\n",
      "Epoch: [1/2], Step: [33500/540], Loss: 0.0317\n",
      "Epoch: [1/2], Step: [33600/540], Loss: 0.0216\n",
      "Epoch: [1/2], Step: [33700/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [33800/540], Loss: 0.4452\n",
      "Epoch: [1/2], Step: [33900/540], Loss: 0.0090\n",
      "Epoch: [1/2], Step: [34000/540], Loss: 0.0504\n",
      "Epoch: [1/2], Step: [34100/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [34200/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [34300/540], Loss: 0.0137\n",
      "Epoch: [1/2], Step: [34400/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [34500/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [34600/540], Loss: 0.0022\n",
      "Epoch: [1/2], Step: [34700/540], Loss: 0.1444\n",
      "Epoch: [1/2], Step: [34800/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [34900/540], Loss: 2.3145\n",
      "Epoch: [1/2], Step: [35000/540], Loss: 0.0018\n",
      "Epoch: [1/2], Step: [35100/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [35200/540], Loss: 0.3056\n",
      "Epoch: [1/2], Step: [35300/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [35400/540], Loss: 0.0263\n",
      "Epoch: [1/2], Step: [35500/540], Loss: 0.0319\n",
      "Epoch: [1/2], Step: [35600/540], Loss: 0.4265\n",
      "Epoch: [1/2], Step: [35700/540], Loss: 0.0018\n",
      "Epoch: [1/2], Step: [35800/540], Loss: 0.0186\n",
      "Epoch: [1/2], Step: [35900/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [36000/540], Loss: 0.2425\n",
      "Epoch: [1/2], Step: [36100/540], Loss: 0.0053\n",
      "Epoch: [1/2], Step: [36200/540], Loss: 6.0270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/2], Step: [36300/540], Loss: 0.0046\n",
      "Epoch: [1/2], Step: [36400/540], Loss: 0.0044\n",
      "Epoch: [1/2], Step: [36500/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [36600/540], Loss: 0.0085\n",
      "Epoch: [1/2], Step: [36700/540], Loss: 0.0023\n",
      "Epoch: [1/2], Step: [36800/540], Loss: 0.0006\n",
      "Epoch: [1/2], Step: [36900/540], Loss: 0.0025\n",
      "Epoch: [1/2], Step: [37000/540], Loss: 0.0286\n",
      "Epoch: [1/2], Step: [37100/540], Loss: 0.0245\n",
      "Epoch: [1/2], Step: [37200/540], Loss: 0.5761\n",
      "Epoch: [1/2], Step: [37300/540], Loss: 0.0111\n",
      "Epoch: [1/2], Step: [37400/540], Loss: 0.0190\n",
      "Epoch: [1/2], Step: [37500/540], Loss: 0.1802\n",
      "Epoch: [1/2], Step: [37600/540], Loss: 0.0010\n",
      "Epoch: [1/2], Step: [37700/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [37800/540], Loss: 0.0027\n",
      "Epoch: [1/2], Step: [37900/540], Loss: 0.3575\n",
      "Epoch: [1/2], Step: [38000/540], Loss: 0.0646\n",
      "Epoch: [1/2], Step: [38100/540], Loss: 2.0010\n",
      "Epoch: [1/2], Step: [38200/540], Loss: 0.0672\n",
      "Epoch: [1/2], Step: [38300/540], Loss: 0.0136\n",
      "Epoch: [1/2], Step: [38400/540], Loss: 0.2325\n",
      "Epoch: [1/2], Step: [38500/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [38600/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [38700/540], Loss: 0.0497\n",
      "Epoch: [1/2], Step: [38800/540], Loss: 0.3757\n",
      "Epoch: [1/2], Step: [38900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [39000/540], Loss: 0.2199\n",
      "Epoch: [1/2], Step: [39100/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [39200/540], Loss: 0.0167\n",
      "Epoch: [1/2], Step: [39300/540], Loss: 2.0662\n",
      "Epoch: [1/2], Step: [39400/540], Loss: 0.4060\n",
      "Epoch: [1/2], Step: [39500/540], Loss: 0.0013\n",
      "Epoch: [1/2], Step: [39600/540], Loss: 0.0443\n",
      "Epoch: [1/2], Step: [39700/540], Loss: 3.9214\n",
      "Epoch: [1/2], Step: [39800/540], Loss: 0.0291\n",
      "Epoch: [1/2], Step: [39900/540], Loss: 0.0056\n",
      "Epoch: [1/2], Step: [40000/540], Loss: 0.0628\n",
      "Epoch: [1/2], Step: [40100/540], Loss: 0.0018\n",
      "Epoch: [1/2], Step: [40200/540], Loss: 0.0023\n",
      "Epoch: [1/2], Step: [40300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [40400/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [40500/540], Loss: 1.2164\n",
      "Epoch: [1/2], Step: [40600/540], Loss: 0.0173\n",
      "Epoch: [1/2], Step: [40700/540], Loss: 0.0020\n",
      "Epoch: [1/2], Step: [40800/540], Loss: 0.0110\n",
      "Epoch: [1/2], Step: [40900/540], Loss: 0.0065\n",
      "Epoch: [1/2], Step: [41000/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [41100/540], Loss: 0.3768\n",
      "Epoch: [1/2], Step: [41200/540], Loss: 0.0015\n",
      "Epoch: [1/2], Step: [41300/540], Loss: 0.0010\n",
      "Epoch: [1/2], Step: [41400/540], Loss: 0.0039\n",
      "Epoch: [1/2], Step: [41500/540], Loss: 0.0149\n",
      "Epoch: [1/2], Step: [41600/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [41700/540], Loss: 0.0067\n",
      "Epoch: [1/2], Step: [41800/540], Loss: 0.0221\n",
      "Epoch: [1/2], Step: [41900/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [42000/540], Loss: 0.9418\n",
      "Epoch: [1/2], Step: [42100/540], Loss: 0.3763\n",
      "Epoch: [1/2], Step: [42200/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [42300/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [42400/540], Loss: 0.0010\n",
      "Epoch: [1/2], Step: [42500/540], Loss: 0.1395\n",
      "Epoch: [1/2], Step: [42600/540], Loss: 0.0133\n",
      "Epoch: [1/2], Step: [42700/540], Loss: 0.2194\n",
      "Epoch: [1/2], Step: [42800/540], Loss: 4.6634\n",
      "Epoch: [1/2], Step: [42900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [43000/540], Loss: 0.0037\n",
      "Epoch: [1/2], Step: [43100/540], Loss: 0.3604\n",
      "Epoch: [1/2], Step: [43200/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [43300/540], Loss: 0.0413\n",
      "Epoch: [1/2], Step: [43400/540], Loss: 0.0038\n",
      "Epoch: [1/2], Step: [43500/540], Loss: 0.0003\n",
      "Epoch: [1/2], Step: [43600/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [43700/540], Loss: 3.7923\n",
      "Epoch: [1/2], Step: [43800/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [43900/540], Loss: 7.1425\n",
      "Epoch: [1/2], Step: [44000/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [44100/540], Loss: 0.0011\n",
      "Epoch: [1/2], Step: [44200/540], Loss: 4.7656\n",
      "Epoch: [1/2], Step: [44300/540], Loss: 0.0082\n",
      "Epoch: [1/2], Step: [44400/540], Loss: 2.6999\n",
      "Epoch: [1/2], Step: [44500/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [44600/540], Loss: 3.6670\n",
      "Epoch: [1/2], Step: [44700/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [44800/540], Loss: 0.3496\n",
      "Epoch: [1/2], Step: [44900/540], Loss: 0.0210\n",
      "Epoch: [1/2], Step: [45000/540], Loss: 0.0019\n",
      "Epoch: [1/2], Step: [45100/540], Loss: 0.8477\n",
      "Epoch: [1/2], Step: [45200/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [45300/540], Loss: 0.0045\n",
      "Epoch: [1/2], Step: [45400/540], Loss: 0.0235\n",
      "Epoch: [1/2], Step: [45500/540], Loss: 0.0156\n",
      "Epoch: [1/2], Step: [45600/540], Loss: 0.0549\n",
      "Epoch: [1/2], Step: [45700/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [45800/540], Loss: 0.1688\n",
      "Epoch: [1/2], Step: [45900/540], Loss: 0.0227\n",
      "Epoch: [1/2], Step: [46000/540], Loss: 0.7123\n",
      "Epoch: [1/2], Step: [46100/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [46200/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [46300/540], Loss: 0.0607\n",
      "Epoch: [1/2], Step: [46400/540], Loss: 0.0200\n",
      "Epoch: [1/2], Step: [46500/540], Loss: 0.0543\n",
      "Epoch: [1/2], Step: [46600/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [46700/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [46800/540], Loss: 0.0098\n",
      "Epoch: [1/2], Step: [46900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [47000/540], Loss: 0.0127\n",
      "Epoch: [1/2], Step: [47100/540], Loss: 0.0017\n",
      "Epoch: [1/2], Step: [47200/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [47300/540], Loss: 0.0009\n",
      "Epoch: [1/2], Step: [47400/540], Loss: 0.1920\n",
      "Epoch: [1/2], Step: [47500/540], Loss: 0.0655\n",
      "Epoch: [1/2], Step: [47600/540], Loss: 0.0494\n",
      "Epoch: [1/2], Step: [47700/540], Loss: 0.3977\n",
      "Epoch: [1/2], Step: [47800/540], Loss: 2.5239\n",
      "Epoch: [1/2], Step: [47900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [48000/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [48100/540], Loss: 0.0190\n",
      "Epoch: [1/2], Step: [48200/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [48300/540], Loss: 1.9917\n",
      "Epoch: [1/2], Step: [48400/540], Loss: 0.1490\n",
      "Epoch: [1/2], Step: [48500/540], Loss: 0.0005\n",
      "Epoch: [1/2], Step: [48600/540], Loss: 0.6992\n",
      "Epoch: [1/2], Step: [48700/540], Loss: 0.0246\n",
      "Epoch: [1/2], Step: [48800/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [48900/540], Loss: 0.2175\n",
      "Epoch: [1/2], Step: [49000/540], Loss: 9.9340\n",
      "Epoch: [1/2], Step: [49100/540], Loss: 0.0438\n",
      "Epoch: [1/2], Step: [49200/540], Loss: 0.0284\n",
      "Epoch: [1/2], Step: [49300/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [49400/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [49500/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [49600/540], Loss: 0.0194\n",
      "Epoch: [1/2], Step: [49700/540], Loss: 0.1372\n",
      "Epoch: [1/2], Step: [49800/540], Loss: 1.0402\n",
      "Epoch: [1/2], Step: [49900/540], Loss: 0.0005\n",
      "Epoch: [1/2], Step: [50000/540], Loss: 0.0047\n",
      "Epoch: [1/2], Step: [50100/540], Loss: 0.0035\n",
      "Epoch: [1/2], Step: [50200/540], Loss: 0.0007\n",
      "Epoch: [1/2], Step: [50300/540], Loss: 0.6596\n",
      "Epoch: [1/2], Step: [50400/540], Loss: 0.0156\n",
      "Epoch: [1/2], Step: [50500/540], Loss: 0.0184\n",
      "Epoch: [1/2], Step: [50600/540], Loss: 0.0059\n",
      "Epoch: [1/2], Step: [50700/540], Loss: 0.0967\n",
      "Epoch: [1/2], Step: [50800/540], Loss: 0.2027\n",
      "Epoch: [1/2], Step: [50900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [51000/540], Loss: 0.0034\n",
      "Epoch: [1/2], Step: [51100/540], Loss: 0.0092\n",
      "Epoch: [1/2], Step: [51200/540], Loss: 0.2980\n",
      "Epoch: [1/2], Step: [51300/540], Loss: 5.7054\n",
      "Epoch: [1/2], Step: [51400/540], Loss: 0.0979\n",
      "Epoch: [1/2], Step: [51500/540], Loss: 0.0135\n",
      "Epoch: [1/2], Step: [51600/540], Loss: 0.0492\n",
      "Epoch: [1/2], Step: [51700/540], Loss: 0.0004\n",
      "Epoch: [1/2], Step: [51800/540], Loss: 0.0012\n",
      "Epoch: [1/2], Step: [51900/540], Loss: 0.0229\n",
      "Epoch: [1/2], Step: [52000/540], Loss: 0.0024\n",
      "Epoch: [1/2], Step: [52100/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [52200/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [52300/540], Loss: 0.0008\n",
      "Epoch: [1/2], Step: [52400/540], Loss: 0.0541\n",
      "Epoch: [1/2], Step: [52500/540], Loss: 0.0028\n",
      "Epoch: [1/2], Step: [52600/540], Loss: 0.0005\n",
      "Epoch: [1/2], Step: [52700/540], Loss: 0.0377\n",
      "Epoch: [1/2], Step: [52800/540], Loss: 0.0001\n",
      "Epoch: [1/2], Step: [52900/540], Loss: 2.2993\n",
      "Epoch: [1/2], Step: [53000/540], Loss: 0.0655\n",
      "Epoch: [1/2], Step: [53100/540], Loss: 0.0002\n",
      "Epoch: [1/2], Step: [53200/540], Loss: 0.0026\n",
      "Epoch: [1/2], Step: [53300/540], Loss: 1.2426\n",
      "Epoch: [1/2], Step: [53400/540], Loss: 0.2630\n",
      "Epoch: [1/2], Step: [53500/540], Loss: 0.1676\n",
      "Epoch: [1/2], Step: [53600/540], Loss: 0.0039\n",
      "Epoch: [1/2], Step: [53700/540], Loss: 0.0063\n",
      "Epoch: [1/2], Step: [53800/540], Loss: 0.0058\n",
      "Epoch: [1/2], Step: [53900/540], Loss: 0.0000\n",
      "Epoch: [1/2], Step: [54000/540], Loss: 0.0021\n",
      "Epoch: [2/2], Step: [100/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [200/540], Loss: 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/2], Step: [300/540], Loss: 8.5069\n",
      "Epoch: [2/2], Step: [400/540], Loss: 0.0176\n",
      "Epoch: [2/2], Step: [500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [600/540], Loss: 5.3242\n",
      "Epoch: [2/2], Step: [700/540], Loss: 0.0030\n",
      "Epoch: [2/2], Step: [800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [900/540], Loss: 0.0025\n",
      "Epoch: [2/2], Step: [1000/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [1100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [1200/540], Loss: 0.4771\n",
      "Epoch: [2/2], Step: [1300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [1400/540], Loss: 1.7572\n",
      "Epoch: [2/2], Step: [1500/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [1600/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [1700/540], Loss: 0.4065\n",
      "Epoch: [2/2], Step: [1800/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [1900/540], Loss: 0.0129\n",
      "Epoch: [2/2], Step: [2000/540], Loss: 0.2538\n",
      "Epoch: [2/2], Step: [2100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [2200/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [2300/540], Loss: 7.6448\n",
      "Epoch: [2/2], Step: [2400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [2500/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [2600/540], Loss: 0.0454\n",
      "Epoch: [2/2], Step: [2700/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [2800/540], Loss: 0.0398\n",
      "Epoch: [2/2], Step: [2900/540], Loss: 0.0037\n",
      "Epoch: [2/2], Step: [3000/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [3100/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [3200/540], Loss: 0.0845\n",
      "Epoch: [2/2], Step: [3300/540], Loss: 0.0087\n",
      "Epoch: [2/2], Step: [3400/540], Loss: 3.8298\n",
      "Epoch: [2/2], Step: [3500/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [3600/540], Loss: 0.0408\n",
      "Epoch: [2/2], Step: [3700/540], Loss: 0.0191\n",
      "Epoch: [2/2], Step: [3800/540], Loss: 0.0903\n",
      "Epoch: [2/2], Step: [3900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [4000/540], Loss: 0.1595\n",
      "Epoch: [2/2], Step: [4100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [4200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [4300/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [4400/540], Loss: 0.0300\n",
      "Epoch: [2/2], Step: [4500/540], Loss: 0.0045\n",
      "Epoch: [2/2], Step: [4600/540], Loss: 0.8768\n",
      "Epoch: [2/2], Step: [4700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [4800/540], Loss: 0.0161\n",
      "Epoch: [2/2], Step: [4900/540], Loss: 0.6236\n",
      "Epoch: [2/2], Step: [5000/540], Loss: 0.4847\n",
      "Epoch: [2/2], Step: [5100/540], Loss: 0.0759\n",
      "Epoch: [2/2], Step: [5200/540], Loss: 0.0029\n",
      "Epoch: [2/2], Step: [5300/540], Loss: 0.0010\n",
      "Epoch: [2/2], Step: [5400/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [5500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [5600/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [5700/540], Loss: 0.0212\n",
      "Epoch: [2/2], Step: [5800/540], Loss: 0.0697\n",
      "Epoch: [2/2], Step: [5900/540], Loss: 0.0010\n",
      "Epoch: [2/2], Step: [6000/540], Loss: 0.4866\n",
      "Epoch: [2/2], Step: [6100/540], Loss: 0.0049\n",
      "Epoch: [2/2], Step: [6200/540], Loss: 0.2023\n",
      "Epoch: [2/2], Step: [6300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [6400/540], Loss: 0.0056\n",
      "Epoch: [2/2], Step: [6500/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [6600/540], Loss: 1.3771\n",
      "Epoch: [2/2], Step: [6700/540], Loss: 0.0141\n",
      "Epoch: [2/2], Step: [6800/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [6900/540], Loss: 0.0019\n",
      "Epoch: [2/2], Step: [7000/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [7100/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [7200/540], Loss: 0.0324\n",
      "Epoch: [2/2], Step: [7300/540], Loss: 0.0014\n",
      "Epoch: [2/2], Step: [7400/540], Loss: 0.0011\n",
      "Epoch: [2/2], Step: [7500/540], Loss: 0.0102\n",
      "Epoch: [2/2], Step: [7600/540], Loss: 0.0236\n",
      "Epoch: [2/2], Step: [7700/540], Loss: 0.0021\n",
      "Epoch: [2/2], Step: [7800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [7900/540], Loss: 0.2337\n",
      "Epoch: [2/2], Step: [8000/540], Loss: 0.0217\n",
      "Epoch: [2/2], Step: [8100/540], Loss: 0.0192\n",
      "Epoch: [2/2], Step: [8200/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [8300/540], Loss: 4.3595\n",
      "Epoch: [2/2], Step: [8400/540], Loss: 0.4657\n",
      "Epoch: [2/2], Step: [8500/540], Loss: 0.0034\n",
      "Epoch: [2/2], Step: [8600/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [8700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [8800/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [8900/540], Loss: 1.4999\n",
      "Epoch: [2/2], Step: [9000/540], Loss: 0.1932\n",
      "Epoch: [2/2], Step: [9100/540], Loss: 0.0384\n",
      "Epoch: [2/2], Step: [9200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [9300/540], Loss: 0.0874\n",
      "Epoch: [2/2], Step: [9400/540], Loss: 0.0104\n",
      "Epoch: [2/2], Step: [9500/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [9600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [9700/540], Loss: 0.0018\n",
      "Epoch: [2/2], Step: [9800/540], Loss: 0.0042\n",
      "Epoch: [2/2], Step: [9900/540], Loss: 0.0095\n",
      "Epoch: [2/2], Step: [10000/540], Loss: 0.0009\n",
      "Epoch: [2/2], Step: [10100/540], Loss: 0.0431\n",
      "Epoch: [2/2], Step: [10200/540], Loss: 0.0119\n",
      "Epoch: [2/2], Step: [10300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [10400/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [10500/540], Loss: 0.0130\n",
      "Epoch: [2/2], Step: [10600/540], Loss: 0.0032\n",
      "Epoch: [2/2], Step: [10700/540], Loss: 0.3590\n",
      "Epoch: [2/2], Step: [10800/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [10900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [11000/540], Loss: 0.6031\n",
      "Epoch: [2/2], Step: [11100/540], Loss: 1.3250\n",
      "Epoch: [2/2], Step: [11200/540], Loss: 0.0211\n",
      "Epoch: [2/2], Step: [11300/540], Loss: 0.0121\n",
      "Epoch: [2/2], Step: [11400/540], Loss: 0.0022\n",
      "Epoch: [2/2], Step: [11500/540], Loss: 0.0306\n",
      "Epoch: [2/2], Step: [11600/540], Loss: 0.0094\n",
      "Epoch: [2/2], Step: [11700/540], Loss: 1.3149\n",
      "Epoch: [2/2], Step: [11800/540], Loss: 4.3520\n",
      "Epoch: [2/2], Step: [11900/540], Loss: 0.4764\n",
      "Epoch: [2/2], Step: [12000/540], Loss: 0.0249\n",
      "Epoch: [2/2], Step: [12100/540], Loss: 0.0016\n",
      "Epoch: [2/2], Step: [12200/540], Loss: 0.0016\n",
      "Epoch: [2/2], Step: [12300/540], Loss: 0.0661\n",
      "Epoch: [2/2], Step: [12400/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [12500/540], Loss: 0.0009\n",
      "Epoch: [2/2], Step: [12600/540], Loss: 1.7838\n",
      "Epoch: [2/2], Step: [12700/540], Loss: 0.0336\n",
      "Epoch: [2/2], Step: [12800/540], Loss: 0.0022\n",
      "Epoch: [2/2], Step: [12900/540], Loss: 0.0010\n",
      "Epoch: [2/2], Step: [13000/540], Loss: 0.2411\n",
      "Epoch: [2/2], Step: [13100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [13200/540], Loss: 7.8685\n",
      "Epoch: [2/2], Step: [13300/540], Loss: 0.0906\n",
      "Epoch: [2/2], Step: [13400/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [13500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [13600/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [13700/540], Loss: 0.0123\n",
      "Epoch: [2/2], Step: [13800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [13900/540], Loss: 0.0058\n",
      "Epoch: [2/2], Step: [14000/540], Loss: 0.0106\n",
      "Epoch: [2/2], Step: [14100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [14200/540], Loss: 0.1809\n",
      "Epoch: [2/2], Step: [14300/540], Loss: 0.9051\n",
      "Epoch: [2/2], Step: [14400/540], Loss: 0.0107\n",
      "Epoch: [2/2], Step: [14500/540], Loss: 0.0043\n",
      "Epoch: [2/2], Step: [14600/540], Loss: 0.0210\n",
      "Epoch: [2/2], Step: [14700/540], Loss: 0.0021\n",
      "Epoch: [2/2], Step: [14800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [14900/540], Loss: 0.3742\n",
      "Epoch: [2/2], Step: [15000/540], Loss: 1.0772\n",
      "Epoch: [2/2], Step: [15100/540], Loss: 0.0294\n",
      "Epoch: [2/2], Step: [15200/540], Loss: 0.0017\n",
      "Epoch: [2/2], Step: [15300/540], Loss: 1.4383\n",
      "Epoch: [2/2], Step: [15400/540], Loss: 0.0010\n",
      "Epoch: [2/2], Step: [15500/540], Loss: 0.0036\n",
      "Epoch: [2/2], Step: [15600/540], Loss: 0.0640\n",
      "Epoch: [2/2], Step: [15700/540], Loss: 0.1060\n",
      "Epoch: [2/2], Step: [15800/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [15900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [16000/540], Loss: 0.0370\n",
      "Epoch: [2/2], Step: [16100/540], Loss: 0.4047\n",
      "Epoch: [2/2], Step: [16200/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [16300/540], Loss: 0.4846\n",
      "Epoch: [2/2], Step: [16400/540], Loss: 0.2595\n",
      "Epoch: [2/2], Step: [16500/540], Loss: 0.0543\n",
      "Epoch: [2/2], Step: [16600/540], Loss: 0.4278\n",
      "Epoch: [2/2], Step: [16700/540], Loss: 1.8867\n",
      "Epoch: [2/2], Step: [16800/540], Loss: 0.0346\n",
      "Epoch: [2/2], Step: [16900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [17000/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [17100/540], Loss: 0.2412\n",
      "Epoch: [2/2], Step: [17200/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [17300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [17400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [17500/540], Loss: 1.3169\n",
      "Epoch: [2/2], Step: [17600/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [17700/540], Loss: 0.2012\n",
      "Epoch: [2/2], Step: [17800/540], Loss: 0.0175\n",
      "Epoch: [2/2], Step: [17900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [18000/540], Loss: 0.0195\n",
      "Epoch: [2/2], Step: [18100/540], Loss: 0.0355\n",
      "Epoch: [2/2], Step: [18200/540], Loss: 0.0434\n",
      "Epoch: [2/2], Step: [18300/540], Loss: 0.0794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/2], Step: [18400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [18500/540], Loss: 0.0028\n",
      "Epoch: [2/2], Step: [18600/540], Loss: 0.0085\n",
      "Epoch: [2/2], Step: [18700/540], Loss: 0.7566\n",
      "Epoch: [2/2], Step: [18800/540], Loss: 0.0434\n",
      "Epoch: [2/2], Step: [18900/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [19000/540], Loss: 0.0140\n",
      "Epoch: [2/2], Step: [19100/540], Loss: 0.0466\n",
      "Epoch: [2/2], Step: [19200/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [19300/540], Loss: 0.0114\n",
      "Epoch: [2/2], Step: [19400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [19500/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [19600/540], Loss: 0.0019\n",
      "Epoch: [2/2], Step: [19700/540], Loss: 7.1031\n",
      "Epoch: [2/2], Step: [19800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [19900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [20000/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [20100/540], Loss: 2.9024\n",
      "Epoch: [2/2], Step: [20200/540], Loss: 1.0420\n",
      "Epoch: [2/2], Step: [20300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [20400/540], Loss: 0.1720\n",
      "Epoch: [2/2], Step: [20500/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [20600/540], Loss: 0.0314\n",
      "Epoch: [2/2], Step: [20700/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [20800/540], Loss: 0.1885\n",
      "Epoch: [2/2], Step: [20900/540], Loss: 0.0041\n",
      "Epoch: [2/2], Step: [21000/540], Loss: 5.3676\n",
      "Epoch: [2/2], Step: [21100/540], Loss: 1.2837\n",
      "Epoch: [2/2], Step: [21200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [21300/540], Loss: 0.0049\n",
      "Epoch: [2/2], Step: [21400/540], Loss: 0.0373\n",
      "Epoch: [2/2], Step: [21500/540], Loss: 2.0730\n",
      "Epoch: [2/2], Step: [21600/540], Loss: 0.0595\n",
      "Epoch: [2/2], Step: [21700/540], Loss: 0.0018\n",
      "Epoch: [2/2], Step: [21800/540], Loss: 0.0024\n",
      "Epoch: [2/2], Step: [21900/540], Loss: 0.1182\n",
      "Epoch: [2/2], Step: [22000/540], Loss: 0.0147\n",
      "Epoch: [2/2], Step: [22100/540], Loss: 0.0014\n",
      "Epoch: [2/2], Step: [22200/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [22300/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [22400/540], Loss: 0.1452\n",
      "Epoch: [2/2], Step: [22500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [22600/540], Loss: 0.0490\n",
      "Epoch: [2/2], Step: [22700/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [22800/540], Loss: 0.1256\n",
      "Epoch: [2/2], Step: [22900/540], Loss: 0.0048\n",
      "Epoch: [2/2], Step: [23000/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [23100/540], Loss: 0.1098\n",
      "Epoch: [2/2], Step: [23200/540], Loss: 0.0042\n",
      "Epoch: [2/2], Step: [23300/540], Loss: 0.4573\n",
      "Epoch: [2/2], Step: [23400/540], Loss: 0.0017\n",
      "Epoch: [2/2], Step: [23500/540], Loss: 0.0053\n",
      "Epoch: [2/2], Step: [23600/540], Loss: 0.0012\n",
      "Epoch: [2/2], Step: [23700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [23800/540], Loss: 0.0017\n",
      "Epoch: [2/2], Step: [23900/540], Loss: 0.0133\n",
      "Epoch: [2/2], Step: [24000/540], Loss: 0.4684\n",
      "Epoch: [2/2], Step: [24100/540], Loss: 0.0075\n",
      "Epoch: [2/2], Step: [24200/540], Loss: 0.0019\n",
      "Epoch: [2/2], Step: [24300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [24400/540], Loss: 0.0167\n",
      "Epoch: [2/2], Step: [24500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [24600/540], Loss: 0.1820\n",
      "Epoch: [2/2], Step: [24700/540], Loss: 0.5948\n",
      "Epoch: [2/2], Step: [24800/540], Loss: 0.0051\n",
      "Epoch: [2/2], Step: [24900/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [25000/540], Loss: 0.0136\n",
      "Epoch: [2/2], Step: [25100/540], Loss: 0.0037\n",
      "Epoch: [2/2], Step: [25200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [25300/540], Loss: 0.3766\n",
      "Epoch: [2/2], Step: [25400/540], Loss: 0.0015\n",
      "Epoch: [2/2], Step: [25500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [25600/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [25700/540], Loss: 0.0487\n",
      "Epoch: [2/2], Step: [25800/540], Loss: 0.0455\n",
      "Epoch: [2/2], Step: [25900/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [26000/540], Loss: 0.0128\n",
      "Epoch: [2/2], Step: [26100/540], Loss: 0.1244\n",
      "Epoch: [2/2], Step: [26200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [26300/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [26400/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [26500/540], Loss: 0.1743\n",
      "Epoch: [2/2], Step: [26600/540], Loss: 10.0454\n",
      "Epoch: [2/2], Step: [26700/540], Loss: 0.3249\n",
      "Epoch: [2/2], Step: [26800/540], Loss: 1.9274\n",
      "Epoch: [2/2], Step: [26900/540], Loss: 0.0115\n",
      "Epoch: [2/2], Step: [27000/540], Loss: 0.0284\n",
      "Epoch: [2/2], Step: [27100/540], Loss: 0.0294\n",
      "Epoch: [2/2], Step: [27200/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [27300/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [27400/540], Loss: 0.0713\n",
      "Epoch: [2/2], Step: [27500/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [27600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [27700/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [27800/540], Loss: 0.0050\n",
      "Epoch: [2/2], Step: [27900/540], Loss: 0.0014\n",
      "Epoch: [2/2], Step: [28000/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [28100/540], Loss: 0.0019\n",
      "Epoch: [2/2], Step: [28200/540], Loss: 0.0058\n",
      "Epoch: [2/2], Step: [28300/540], Loss: 0.0034\n",
      "Epoch: [2/2], Step: [28400/540], Loss: 0.2705\n",
      "Epoch: [2/2], Step: [28500/540], Loss: 0.0011\n",
      "Epoch: [2/2], Step: [28600/540], Loss: 0.0015\n",
      "Epoch: [2/2], Step: [28700/540], Loss: 0.0140\n",
      "Epoch: [2/2], Step: [28800/540], Loss: 0.0640\n",
      "Epoch: [2/2], Step: [28900/540], Loss: 3.0747\n",
      "Epoch: [2/2], Step: [29000/540], Loss: 0.0343\n",
      "Epoch: [2/2], Step: [29100/540], Loss: 0.0985\n",
      "Epoch: [2/2], Step: [29200/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [29300/540], Loss: 0.0181\n",
      "Epoch: [2/2], Step: [29400/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [29500/540], Loss: 0.9745\n",
      "Epoch: [2/2], Step: [29600/540], Loss: 0.0010\n",
      "Epoch: [2/2], Step: [29700/540], Loss: 0.0388\n",
      "Epoch: [2/2], Step: [29800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [29900/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [30000/540], Loss: 0.1112\n",
      "Epoch: [2/2], Step: [30100/540], Loss: 0.0230\n",
      "Epoch: [2/2], Step: [30200/540], Loss: 0.0074\n",
      "Epoch: [2/2], Step: [30300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [30400/540], Loss: 0.0409\n",
      "Epoch: [2/2], Step: [30500/540], Loss: 0.0014\n",
      "Epoch: [2/2], Step: [30600/540], Loss: 0.0849\n",
      "Epoch: [2/2], Step: [30700/540], Loss: 0.0194\n",
      "Epoch: [2/2], Step: [30800/540], Loss: 0.0093\n",
      "Epoch: [2/2], Step: [30900/540], Loss: 0.0786\n",
      "Epoch: [2/2], Step: [31000/540], Loss: 0.0886\n",
      "Epoch: [2/2], Step: [31100/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [31200/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [31300/540], Loss: 0.1009\n",
      "Epoch: [2/2], Step: [31400/540], Loss: 0.0255\n",
      "Epoch: [2/2], Step: [31500/540], Loss: 0.6507\n",
      "Epoch: [2/2], Step: [31600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [31700/540], Loss: 0.0819\n",
      "Epoch: [2/2], Step: [31800/540], Loss: 1.2852\n",
      "Epoch: [2/2], Step: [31900/540], Loss: 0.0016\n",
      "Epoch: [2/2], Step: [32000/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [32100/540], Loss: 0.0181\n",
      "Epoch: [2/2], Step: [32200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [32300/540], Loss: 0.0026\n",
      "Epoch: [2/2], Step: [32400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [32500/540], Loss: 0.2191\n",
      "Epoch: [2/2], Step: [32600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [32700/540], Loss: 0.0078\n",
      "Epoch: [2/2], Step: [32800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [32900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [33000/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [33100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [33200/540], Loss: 0.0041\n",
      "Epoch: [2/2], Step: [33300/540], Loss: 0.0186\n",
      "Epoch: [2/2], Step: [33400/540], Loss: 0.8784\n",
      "Epoch: [2/2], Step: [33500/540], Loss: 0.0017\n",
      "Epoch: [2/2], Step: [33600/540], Loss: 0.5153\n",
      "Epoch: [2/2], Step: [33700/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [33800/540], Loss: 0.0334\n",
      "Epoch: [2/2], Step: [33900/540], Loss: 1.2211\n",
      "Epoch: [2/2], Step: [34000/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [34100/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [34200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [34300/540], Loss: 0.0369\n",
      "Epoch: [2/2], Step: [34400/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [34500/540], Loss: 0.1097\n",
      "Epoch: [2/2], Step: [34600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [34700/540], Loss: 0.0699\n",
      "Epoch: [2/2], Step: [34800/540], Loss: 0.0074\n",
      "Epoch: [2/2], Step: [34900/540], Loss: 0.0033\n",
      "Epoch: [2/2], Step: [35000/540], Loss: 0.2955\n",
      "Epoch: [2/2], Step: [35100/540], Loss: 0.0123\n",
      "Epoch: [2/2], Step: [35200/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [35300/540], Loss: 0.0009\n",
      "Epoch: [2/2], Step: [35400/540], Loss: 0.0018\n",
      "Epoch: [2/2], Step: [35500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [35600/540], Loss: 0.8559\n",
      "Epoch: [2/2], Step: [35700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [35800/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [35900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [36000/540], Loss: 0.0035\n",
      "Epoch: [2/2], Step: [36100/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [36200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [36300/540], Loss: 0.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/2], Step: [36400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [36500/540], Loss: 1.0180\n",
      "Epoch: [2/2], Step: [36600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [36700/540], Loss: 0.0475\n",
      "Epoch: [2/2], Step: [36800/540], Loss: 3.5548\n",
      "Epoch: [2/2], Step: [36900/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [37000/540], Loss: 0.3113\n",
      "Epoch: [2/2], Step: [37100/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [37200/540], Loss: 0.0444\n",
      "Epoch: [2/2], Step: [37300/540], Loss: 0.0012\n",
      "Epoch: [2/2], Step: [37400/540], Loss: 0.0159\n",
      "Epoch: [2/2], Step: [37500/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [37600/540], Loss: 0.0073\n",
      "Epoch: [2/2], Step: [37700/540], Loss: 0.0608\n",
      "Epoch: [2/2], Step: [37800/540], Loss: 0.0142\n",
      "Epoch: [2/2], Step: [37900/540], Loss: 1.1387\n",
      "Epoch: [2/2], Step: [38000/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [38100/540], Loss: 0.0255\n",
      "Epoch: [2/2], Step: [38200/540], Loss: 0.3631\n",
      "Epoch: [2/2], Step: [38300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [38400/540], Loss: 1.0565\n",
      "Epoch: [2/2], Step: [38500/540], Loss: 0.0386\n",
      "Epoch: [2/2], Step: [38600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [38700/540], Loss: 0.0012\n",
      "Epoch: [2/2], Step: [38800/540], Loss: 0.0011\n",
      "Epoch: [2/2], Step: [38900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [39000/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [39100/540], Loss: 0.0030\n",
      "Epoch: [2/2], Step: [39200/540], Loss: 0.0145\n",
      "Epoch: [2/2], Step: [39300/540], Loss: 0.0052\n",
      "Epoch: [2/2], Step: [39400/540], Loss: 0.0017\n",
      "Epoch: [2/2], Step: [39500/540], Loss: 0.0099\n",
      "Epoch: [2/2], Step: [39600/540], Loss: 0.4078\n",
      "Epoch: [2/2], Step: [39700/540], Loss: 0.6426\n",
      "Epoch: [2/2], Step: [39800/540], Loss: 0.0580\n",
      "Epoch: [2/2], Step: [39900/540], Loss: 0.0743\n",
      "Epoch: [2/2], Step: [40000/540], Loss: 2.9511\n",
      "Epoch: [2/2], Step: [40100/540], Loss: 0.0011\n",
      "Epoch: [2/2], Step: [40200/540], Loss: 0.0074\n",
      "Epoch: [2/2], Step: [40300/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [40400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [40500/540], Loss: 0.0084\n",
      "Epoch: [2/2], Step: [40600/540], Loss: 0.3942\n",
      "Epoch: [2/2], Step: [40700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [40800/540], Loss: 0.0039\n",
      "Epoch: [2/2], Step: [40900/540], Loss: 5.3407\n",
      "Epoch: [2/2], Step: [41000/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [41100/540], Loss: 0.1198\n",
      "Epoch: [2/2], Step: [41200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [41300/540], Loss: 0.0135\n",
      "Epoch: [2/2], Step: [41400/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [41500/540], Loss: 1.6554\n",
      "Epoch: [2/2], Step: [41600/540], Loss: 0.0145\n",
      "Epoch: [2/2], Step: [41700/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [41800/540], Loss: 0.0014\n",
      "Epoch: [2/2], Step: [41900/540], Loss: 0.2070\n",
      "Epoch: [2/2], Step: [42000/540], Loss: 2.8803\n",
      "Epoch: [2/2], Step: [42100/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [42200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [42300/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [42400/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [42500/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [42600/540], Loss: 1.0675\n",
      "Epoch: [2/2], Step: [42700/540], Loss: 0.0500\n",
      "Epoch: [2/2], Step: [42800/540], Loss: 0.0602\n",
      "Epoch: [2/2], Step: [42900/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [43000/540], Loss: 0.0090\n",
      "Epoch: [2/2], Step: [43100/540], Loss: 0.3761\n",
      "Epoch: [2/2], Step: [43200/540], Loss: 0.0040\n",
      "Epoch: [2/2], Step: [43300/540], Loss: 0.1427\n",
      "Epoch: [2/2], Step: [43400/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [43500/540], Loss: 0.2337\n",
      "Epoch: [2/2], Step: [43600/540], Loss: 0.1149\n",
      "Epoch: [2/2], Step: [43700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [43800/540], Loss: 0.1284\n",
      "Epoch: [2/2], Step: [43900/540], Loss: 0.0079\n",
      "Epoch: [2/2], Step: [44000/540], Loss: 0.2702\n",
      "Epoch: [2/2], Step: [44100/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [44200/540], Loss: 0.0008\n",
      "Epoch: [2/2], Step: [44300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [44400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [44500/540], Loss: 0.0013\n",
      "Epoch: [2/2], Step: [44600/540], Loss: 0.0581\n",
      "Epoch: [2/2], Step: [44700/540], Loss: 0.0124\n",
      "Epoch: [2/2], Step: [44800/540], Loss: 0.2271\n",
      "Epoch: [2/2], Step: [44900/540], Loss: 0.0570\n",
      "Epoch: [2/2], Step: [45000/540], Loss: 0.0187\n",
      "Epoch: [2/2], Step: [45100/540], Loss: 2.4207\n",
      "Epoch: [2/2], Step: [45200/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [45300/540], Loss: 0.0409\n",
      "Epoch: [2/2], Step: [45400/540], Loss: 0.4036\n",
      "Epoch: [2/2], Step: [45500/540], Loss: 0.0322\n",
      "Epoch: [2/2], Step: [45600/540], Loss: 0.9229\n",
      "Epoch: [2/2], Step: [45700/540], Loss: 0.0023\n",
      "Epoch: [2/2], Step: [45800/540], Loss: 0.0119\n",
      "Epoch: [2/2], Step: [45900/540], Loss: 0.0054\n",
      "Epoch: [2/2], Step: [46000/540], Loss: 0.0919\n",
      "Epoch: [2/2], Step: [46100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [46200/540], Loss: 0.1615\n",
      "Epoch: [2/2], Step: [46300/540], Loss: 0.0004\n",
      "Epoch: [2/2], Step: [46400/540], Loss: 3.4323\n",
      "Epoch: [2/2], Step: [46500/540], Loss: 0.0023\n",
      "Epoch: [2/2], Step: [46600/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [46700/540], Loss: 0.0072\n",
      "Epoch: [2/2], Step: [46800/540], Loss: 0.1239\n",
      "Epoch: [2/2], Step: [46900/540], Loss: 0.0040\n",
      "Epoch: [2/2], Step: [47000/540], Loss: 0.1500\n",
      "Epoch: [2/2], Step: [47100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [47200/540], Loss: 0.0374\n",
      "Epoch: [2/2], Step: [47300/540], Loss: 0.0035\n",
      "Epoch: [2/2], Step: [47400/540], Loss: 0.0767\n",
      "Epoch: [2/2], Step: [47500/540], Loss: 0.0011\n",
      "Epoch: [2/2], Step: [47600/540], Loss: 0.0052\n",
      "Epoch: [2/2], Step: [47700/540], Loss: 0.5809\n",
      "Epoch: [2/2], Step: [47800/540], Loss: 2.3189\n",
      "Epoch: [2/2], Step: [47900/540], Loss: 0.0050\n",
      "Epoch: [2/2], Step: [48000/540], Loss: 0.1588\n",
      "Epoch: [2/2], Step: [48100/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [48200/540], Loss: 0.0739\n",
      "Epoch: [2/2], Step: [48300/540], Loss: 2.4390\n",
      "Epoch: [2/2], Step: [48400/540], Loss: 0.0071\n",
      "Epoch: [2/2], Step: [48500/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [48600/540], Loss: 0.0034\n",
      "Epoch: [2/2], Step: [48700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [48800/540], Loss: 0.0037\n",
      "Epoch: [2/2], Step: [48900/540], Loss: 13.0417\n",
      "Epoch: [2/2], Step: [49000/540], Loss: 0.3354\n",
      "Epoch: [2/2], Step: [49100/540], Loss: 0.0253\n",
      "Epoch: [2/2], Step: [49200/540], Loss: 0.2186\n",
      "Epoch: [2/2], Step: [49300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [49400/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [49500/540], Loss: 0.4845\n",
      "Epoch: [2/2], Step: [49600/540], Loss: 0.0219\n",
      "Epoch: [2/2], Step: [49700/540], Loss: 0.0007\n",
      "Epoch: [2/2], Step: [49800/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [49900/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [50000/540], Loss: 0.7551\n",
      "Epoch: [2/2], Step: [50100/540], Loss: 0.4372\n",
      "Epoch: [2/2], Step: [50200/540], Loss: 0.0870\n",
      "Epoch: [2/2], Step: [50300/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [50400/540], Loss: 0.0054\n",
      "Epoch: [2/2], Step: [50500/540], Loss: 0.0165\n",
      "Epoch: [2/2], Step: [50600/540], Loss: 11.0182\n",
      "Epoch: [2/2], Step: [50700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [50800/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [50900/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [51000/540], Loss: 0.0507\n",
      "Epoch: [2/2], Step: [51100/540], Loss: 0.0487\n",
      "Epoch: [2/2], Step: [51200/540], Loss: 0.0194\n",
      "Epoch: [2/2], Step: [51300/540], Loss: 0.0394\n",
      "Epoch: [2/2], Step: [51400/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [51500/540], Loss: 0.0041\n",
      "Epoch: [2/2], Step: [51600/540], Loss: 0.0179\n",
      "Epoch: [2/2], Step: [51700/540], Loss: 0.0089\n",
      "Epoch: [2/2], Step: [51800/540], Loss: 0.0529\n",
      "Epoch: [2/2], Step: [51900/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [52000/540], Loss: 2.8082\n",
      "Epoch: [2/2], Step: [52100/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [52200/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [52300/540], Loss: 0.0056\n",
      "Epoch: [2/2], Step: [52400/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [52500/540], Loss: 0.0003\n",
      "Epoch: [2/2], Step: [52600/540], Loss: 0.6137\n",
      "Epoch: [2/2], Step: [52700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [52800/540], Loss: 0.0006\n",
      "Epoch: [2/2], Step: [52900/540], Loss: 0.0002\n",
      "Epoch: [2/2], Step: [53000/540], Loss: 0.0240\n",
      "Epoch: [2/2], Step: [53100/540], Loss: 1.5839\n",
      "Epoch: [2/2], Step: [53200/540], Loss: 0.0005\n",
      "Epoch: [2/2], Step: [53300/540], Loss: 0.0001\n",
      "Epoch: [2/2], Step: [53400/540], Loss: 8.3404\n",
      "Epoch: [2/2], Step: [53500/540], Loss: 0.1999\n",
      "Epoch: [2/2], Step: [53600/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [53700/540], Loss: 0.0000\n",
      "Epoch: [2/2], Step: [53800/540], Loss: 0.0018\n",
      "Epoch: [2/2], Step: [53900/540], Loss: 0.0584\n",
      "Epoch: [2/2], Step: [54000/540], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "% (epoch+1, num_epochs, i+1, len(train_loader)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_final_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
